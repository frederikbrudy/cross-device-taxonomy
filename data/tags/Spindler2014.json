{
  "user_device_rel": "1 person to n devices; n people to m devices",
  "target_users": "Group work; Individual",
  "pid": "Spindler2014",
  "focus": "Hardware; Software",
  "device_models": "Kinect; iPad; custom tabletop",
  "cost": "900$ (Kinect and one iPad)",
  "device_mount": "Handheld; Placed loosely around user (e.g., table); tabletop",
  "tracking_rate": "18-20Hz for one tracked display. Each additional display consumes 2-3ms extra per frame.",
  "pid_done": "2",
  "scale": "Social space; Near, personal space",
  "input_modalities": "3D gestures; Touch",
  "devices_included": "Phone; Tablet; paper / cardboard; Tabletop, large horizontal display",
  "use_cases_desc": "- data exploration of high res images, e.g. a cut through a rat ambyro (also see magic lense project)\r\n- \"in a shopping mall, several users could simultaneously navigate through the mall's map that is displayed on one of many large public displays by holding and moving their mobile phones on and above the big screen. In the same way, two of these people could hold their phones close to each other in order to discuss a private matter\"",
  "evaluation": "Quality measurements (e.g., accuracy of tracking); Technical performance (speed)",
  "contentlength": "11",
  "contribution_desc": "The paper describes a design space for tangible displays and a requirement analysis for technical realization of tangible, spatially aware displays. \r\n\r\nThe authors lay out two classes of spatially aware displays: active (e.g. iPads) and projective (e.g. cardboard rectangles where content is projected on) displays.\r\n\r\nFurther the authors implemented a prototype system that uses the depth image of a ceiling mounted Kinect camera to track iPads as well as paper displays (rectangular, square, circle) in mid-air. Through projection on the paper, these can be used as interactive displays. ",
  "tracking_accuracy": "Comparison to OptiTrack system: we detected an average difference of 4 mm (X-axis, SD = 3.0 mm), 5 mm (Y-axis, SD = 3.6 mm), and 9 mm (Z-axis, SD = 7.0 mm) between OptiTrack and their system. a maximum error of about 5 degrees, the computation of display normals (local Z-axes of displays)",
  "pid_access": 1532449398,
  "papertype": "Full paper",
  "tracking_characteristic": "Outside-in tracking; Tracking devices only; Location 3D",
  "output_modalities": "Screen output; projection",
  "deployment": "Lab study",
  "interaction_techniques": "Data exploration; Visualisation; Data transfer/sharing",
  "fabrication": "Kinect mounted to a horizontal bar on ceiling",
  "tracking_reliability": "\"the system can get confused occasionally, such as when two displays of the same type (e.g., the iPad) get too close together\"; when tracking partially overlapping displays, only the top most display is tracked; displays that are flat on the tablet cannot be reliably tracked as the depth resolution of the Kinect is not precise enough. ",
  "connection_classification": "Via remote server",
  "toolkits": "Qt library",
  "use_cases": "data exploration; medical applications; shopping mall navigation",
  "tracking_tech": "Kinect",
  "contribution": "Tracking technology; design space; Interaction techniques",
  "crossdevice_def": "\"[...] spatial input is a powerful input channel that integrates particularly well within multi-display multi-user environments and supports co-located parallel work and collaboration explicitly.\"\r\n\r\n\"two major features of this design space are (1) the support for co-located parallel work and collaboration by combining multiple personal handheld displays with one or more shared global displays and (2) the simultaneous support of different input modalities that are close to what users are familiar with in everyday life.\""
}